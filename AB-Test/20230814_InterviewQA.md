## 某APP推出会员付费活动，上线第一周，会员付费订单数不及预期，请问你会如何分析？
- 目标确认：首先验证数据准确性，确保没有遗漏或者错误，同时，验证是否是上线时间、或新奇效应带来的偏差（观察历史数据），从而验证预期目标是否合理；
- 用户参与度：分析用户在活动页面的参与情况，活动页面访问量-点击率-跳出量，是否需要优化页面设计或者提高宣传成本；
- 漏斗转化分析：用户访问-点击-选择套餐或产品-付费等，观察流失率较高的环节，定向进行优化；
- 用户细分：按照用户画像对人群进行细分，分析不同人群的购买行为，找出潜在的优化方向（年龄、地域、新老用户）
- 价格敏感度：分析用户对会员付费价格的敏感度，尝试调整策略，发放优惠券、折扣等优惠措施（uplift找用户）
- 产品体验：用户调查、在线反馈，收集满意度
- 竞品分析：分析竞对的活动效果和付费策略，了解用户的需求
- 先排查数据准确性，排除上报错误问题，然后分析外部因素（大盘数据+竞争对手数据情况）+内部因素（切片分析+路径分析）。

## 假如你是CS:GO的游戏分析师，如何提升你的MAU？
- 拉新：营销推广，广告、合作、赞助，游戏主播、网红等提升产品影响力
- 促活：内容及时更新，提升用户活跃度，活动、场景、地图、模式、武器等，吸引玩家参与
- 留存：新老用户留存，新用户新手引导、降低门槛、体验乐趣；老用户新颖玩法、合理激励
- 产品体验：重视用户反馈
- 数据驱动：建立完善的监控报表体系，观察关键指标，针对有问题的指标进行定向优化

## 假如你的产品MAU没变，WAU降低，你会如何分析？
- 说明用户活跃度降低了，来的少了，对该产品兴趣降低或有其他替代选项；
- 用户行为分析：观察用户行为指标，单次使用时长、来访频次、参与活动时长等等，找到具体原因；
- 用户分层：观察不同用户群体行文，新老、重度、轻度用户；
- 内容更新：是不是更新不如预期
- 竞品分析：市场替代性竞品
- 市场或季节因素：是否因为特殊时间影响或重大赛事（世界杯）

## 如何证明AB实验的差异不是分流不一致引起的？为什么可能分流不一致
- 检查分流机制是否正确执行？符合平行趋势检验
- 对比分流用户特征：性别、年龄、地域等
- 时间因素：是否有不同时间段的影响

- 为什么可能？分流算法、自选择偏差、外部因素

## 执行多元线性回归之前需要注意的几个假设
- 线性关系：自变量和因变量之间应存在线性关系。这意味着，当自变量改变时，因变量也会按照一定的比例改变。这可以通过散点图或相关性分析来检查。
- 独立性：观测值之间应该是独立的，也就是说，一个观测值的出现不应该影响到其他观测值的出现。在时间序列数据或空间数据中，这个假设可能不成立。
- 同方差性（Homoscedasticity）：对于所有的自变量，误差项（即残差）的方差应该是常数。如果方差随着自变量的增加或减少而改变，那么就存在异方差性。这可以通过残差图来检查。
- 正态性：对于任何固定的自变量值，因变量的值（或误差项）应该遵循正态分布。这可以通过正态概率图（Normal Probability Plot）或者Shapiro-Wilk检验来检查。
- 无多重共线性：自变量之间不应该存在完全的线性关系，也就是说，一个自变量不应该是其他自变量的精确线性组合。如果存在多重共线性，可能会导致回归系数的估计不准确。这可以通过方差膨胀因子（Variance Inflation Factor，VIF）来检查。

## XGBoost原理？
- XGBoost属于集成学习中boost方法的集大成者，是基于GBDT算法的优化，boost方法属于是加性模型，每次只训练一个分类或回归树，后一个模型基于前一个的残差继续学习，通过梯度下降最小化损失函数；XGBoost是对GBDT的优化，引入二阶导数、正则化项，特征重要性、缺失值补充等，快速收敛、并行计算

## DBSCAN\KMEANS\层次聚类差异
- DBSCAN
  - 初始化中心点，按照距离和最小数量找邻居点，不满足则为噪声点；
  - 遍历非中心点和邻居点，开始递归查找

## 抖音和微信有什么差异，有哪些可以借鉴的地方？
我是从平台（分发机制/流量入口）、游戏（类型/功能）、用户画像展开陈述的，不知道是不是最优答案，大家有更好的思路也欢迎探讨~
借鉴的点的话可以从字节小游戏面临的问题+解决对策来展开，我认为字节小游戏面临认知度低、入口少、用户付费水平低、社交生态薄弱的问题，对策也针对这些方面展开即可。

## 常见的统计指标：
- 描述性统计：这是用来描述、概括或者总结数据特征的统计方法。常见的描述性统计指标包括：
  - 中位数：一组数据中的中间值，将数据集分为两个等分。
  - 方差：衡量数据点与平均值之间差异的度量。方差越大，数据的分散程度越高。
  - 均值：所有数据的平均值。
  - 标准差：方差的平方根，用于衡量数据的离散程度。
- 独立/相关事件：在概率论中，如果两个事件的发生不互相影响，那么这两个事件就是独立的。如果一个事件的发生影响了另一个事件的发生，那么这两个事件就是相关的。
- 期望：在概率论中，期望是试验结果的加权平均，权重是每个结果的概率。
- 概率分布：描述一个随机变量在各种取值下的概率。常见的概率分布包括二项分布、正态分布、泊松分布等。
- 置信区间：在统计推断中，置信区间是对某个未知参数的可能取值范围的估计。
- 假设检验：是一种统计推断方法，用于检验一个关于总体参数的假设是否成立。
- 回归分析：是一种预测模型，用于研究一个变量（因变量）与一个或多个变量（自变量）之间的关系。
- 协方差：衡量两个变量的总体误差。
- 相关系数：衡量两个变量之间的线性关系的强度和方向。
- 偏度：衡量数据分布的不对称性。
- 峰度：衡量数据分布的尖锐程度，反映了数据分布的陡峭或平坦程度相对于正态分布的情况。

## 如何理解Z得分
- z分位数 z=(x−μ)/σ，表示变量到样本均值的距离是多少个标准差，是在在符合正态分布的情况下，衡量不同事件的标准化方法。将 z-score 和表中对应，可得出样本在整个分布中的水平

## 用户画像体系：
- 数据收集：收集用户基本信息和行为数据
- 用户分群：按照不同的标签，性别、年龄、地理位置、兴趣爱好等因素进行划分，确保分群具有一定的区分度
- 用户特征分析：对每个用户群体进行深入分析，了解特征和行为模式，消费习惯、兴趣爱好、购买偏好等
- 用户需求和行为预测
- 用户画像指标：
  - 基本信息
  - 行为数据（浏览、频次、停留时间）
  - 兴趣爱好
  - 社交行为
  - 购买偏好
  - 反馈评价
- 不断收集、不断更新

## 简单介绍下贝叶斯分类的应用和满足的假设
- 贝叶斯分类，利用一些先验知识来计算某个事件发生的概率，P(a|b) = P（b|a）*P(a)/P(b)
- 邮件分类，已知垃圾邮件有“中大奖”的概率、垃圾邮件概率、含“中大奖”概率，可以计算出来含“中大奖”多大可能是垃圾邮件
- 满足假设：1、先验概率；2、独立性假设；3、数据稀疏

## 决策树算法的注意事项
1、避免过拟合：加大数据、观察泛化误差曲线、降低树深度、注意剪枝
2、特征选择：选择合适的特征，避免冗余
3、处理连续值和缺失值

## 参数估计和假设检验：
- 参数估计和假设检验是统计学中两个非常重要的概念。
  - 参数估计：参数估计是指根据样本数据来估计总体参数的过程。例如，我们可能想要估计一个总体的平均值或者方差。参数估计可以分为点估计和区间估计。点估计是对参数的单个值的估计，而区间估计则给出一个可能包含参数真值的区间。参数估计常用于机器学习和数据分析中，例如在构建回归模型时，我们需要估计模型的参数。
  - 假设检验：假设检验是一种统计推断方法，用于检验一个关于总体参数的假设是否成立。假设检验的过程通常包括提出零假设和备选假设，选择适当的检验统计量，计算p值，然后根据p值来决定是否拒绝零假设。假设检验常用于科学研究和数据分析中，例如我们可能想要检验两组数据的平均值是否有显著差异。
- 总的来说，参数估计和假设检验都是统计推断的重要方法，它们在各种场景中都有广泛的应用。参数估计主要用于估计模型参数，为数据建模和预测提供基础；假设检验则主要用于验证某个假设是否成立，帮助我们理解数据和做出决策。

## SVM的优缺点
- 原始SVM用于二分类，线性可分：找超平面，线性不可分：加核函数到高维空间
- 不适用于多分类问题，计算复杂度比较高

## 标准差和标准误差
- 标准差用于衡量数据的离散程度，而标准误差用于衡量估计值的精确性。
- 标准差描述了数据的分布情况，而标准误差描述了估计值与真实值之间的差异。
- 标准差是对数据集合的统计量，而标准误差是对估计值的统计量。

## ab test的流程
- 确定目标和假设（施加某个动作会不会产生显著的影响）
- 选取合适的指标（评价指标、护栏指标），注意可量化性、敏感性和稳定性
  - 检测单次变化时，一般选用短期指标
  - 检测长期持续性变化时，一般选用长期指标
  - 可用AA test来检测敏感性和稳定性
  - 可选择综合指标来进行总体评价，还可规避多重检定问题
- 确定实验单位（用户、session、页面）
- 计算样本量
  - α、β、样本方差、想要提升的目标量级
  - 如何估算目标量级：投入产出比，波动范围
- 计算实验时间
- 分析测试结果
  - 检测特征分布是否相似，是否做到了随机
  - 均值类指标用t检验，概率类指标用z检验
  - 用P值、置信区间来判断结果

## 双十一等不适合ab test的活动，该用什么方式来进行监测呢？
- 对比分析：对比活动前后的销售数据，各项指标来评估活动效果；对比同期竞对数据；对比历年同期数据，消除季节性和行业趋势影响
- 预后对照研究：基于历史数据建立预测模型，预测如果没有活动，正常的营业额是多少，差异部分即为效果；
- 关键KPI效果：持续跟踪关键KPI指标，评估活动效果
- 用户调研、社交媒体分析、长期影响分析等

## L1和L2正则化有什么不同？
- 两者都是机器学习常用的正则化方法，用于防止过拟合和控制模型的复杂度
- L1，lasso，模型参数的绝对值之和，可用于特征选择，倾向于将不相关的特征或冗余特征系数设为0
- L2，岭回归，模型参数的平方和的平方根，将参数的平方和控制
- 最大区别，L1会将些不相关的系数设为0；L2不会

## Random Forest和XGBoost各有什么优劣，该如何进行选择？
- 随机森林：鲁棒性，能处理缺失值和不平衡数据集；能提供特征重要性排序；可以并行化处理
- XGBoost：高性能，处理大规模数据集；灵活性，自定义损失函数
- 数据集规模大、特征维数高，用XGBoost；如果数据集包含噪声、异常值或缺失值，随机森林更适合

## 样本不均衡该如何处理？
- 重采样
  - 过采样：增加少数类样本的数量，复制或合成
  - 欠采样：减少多数类样本的数量
  - 混合采样：过采样+欠采样
- 类别权重：调整少数类中的类别权重
- 调整分类阈值：使得分类器更倾向于将样本预测为少数类
- 生成新特征：创建新特征
- 集成学习方法，随机森林等，有鲁棒性
- 异常检测

## 梯度消失是什么？该如何解决？
- 反向传播时激活函数是sigmoid，在输入较大或较小时，梯度会非常小接近于0，导致无法拟合
- 调整激活函数，如relu
- 梯度裁剪，限制梯度的范围
- 合适的权重初始化

## 召全和召准
- 召全，全部的正样本里有多少回来了
- 召准，返回的正样本里有多少是正确的
- F1-SCORE
- ROC曲线和AUC面积，按照正例从大到小排序，逐个增加正例比例，正确的话纵向、错误的话横向，连线，计算面积

## Bagging和Boosting
- Bagging:从原始数据集中有放回地随机抽样生成多个子样本集，然后使用这些子样本集分别训练独立的基学习器，最后通过投票或平均等方式进行集成
- Boosting:迭代地训练一系列的弱学习器，每个弱学习器都会根据前一个学习器的表现进行调整，使得模型逐步提高性能
- Bagging适用于高方差的模型，可以减少模型的方差，提高模型的稳定性和泛化能力。它的优点在于并行化处理和减少方差，但可能会忽略样本之间的相关性
- Boosting适用于高偏差的模型，可以减少模型的偏差，提高模型的预测能力

決策樹是怎麼建立的（要解釋 Information gain 與 Gini impurity）
隨機森林實際上是指什麼東西隨機？
請介紹深度學習會遇到的 Underflow 與 Overflow 以及建模過程怎麼看出這兩個問題